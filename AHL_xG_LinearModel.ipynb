{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AHL-xG-LinearModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQ8E5mZfg/315SIngxyehD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-wisniewski/xG-LinearModel/blob/main/AHL_xG_LinearModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydtHehAMjYyR"
      },
      "source": [
        "# Acknowledgements\n",
        "\n",
        "This project is heavily based on the linear model found here: https://www.tensorflow.org/tutorials/estimator/linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDoI6m4LQUll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac59b277-660f-40ab-fd03-26c7f104cb13"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "\r\n",
        "!pip install -q sklearn\r\n",
        "\r\n",
        "#from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt # Dataset visualization.\r\n",
        "import numpy as np              # Low-level numerical Python library.\r\n",
        "import pandas as pd             # Higher-level numerical Python library.\r\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ-PHCkjZpzq"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Import scraped data\n",
        "\n",
        "This step imports scraped event data (using ahl_scraper.py) from a csv file. Once imported, the labels and data are separated.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evL7TpeBZ03k"
      },
      "source": [
        "#import training and test data from csv's\r\n",
        "# training data is from game id's 1017122 to 1020000\r\n",
        "xg_df_train = pd.read_csv('https://github.com/r-wisniewski/xG-LinearModel/blob/main/training.csv')\r\n",
        "# testing data is from game id's 1020001 to 1020558. 1020558 is the latest game we have data for\r\n",
        "xg_df_testing = pd.read_csv('https://github.com/r-wisniewski/xG-LinearModel/blob/main/testing.csv')\r\n",
        "\r\n",
        "# separate the labels and data\r\n",
        "y_train = xg_df_train.pop('Goal')\r\n",
        "y_testing = xg_df_testing.pop('Goal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld_rsVltfW7q"
      },
      "source": [
        "### Check the imported data\n",
        "\n",
        "Let's have a quick look at what data has been imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC9dQWu9fUch"
      },
      "source": [
        "#check the first few rows of both dataframes\n",
        "xg_df_train.head()\n",
        "t_train.head()\n",
        "\n",
        "#check the first few rows of both dataframes\n",
        "xg_df_testing.head()\n",
        "y_testing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-666rU9qZHM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Let's train!\n",
        "Now that both the training and test data have been collected, let's train the model!\n",
        "\n",
        "Since all the data is numerical, there is no need to convert any categorical data to numerical. Newer AHL game summaries are beginning to track types of shots, when enough of those game summaries are available we could implement shot type as an additional feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3Fh8RlrIDW"
      },
      "source": [
        "### Create the input function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyeZIbiQrNAt"
      },
      "source": [
        "# data_df = all data in table form, label_df = all associated labels in table form\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    # Convert the pandas dataframe into a tf.data.Dataset object. We want to convert our pandas \"table\" to this new object type before processing.\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its associated label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  ####### return a function object for use ######\n",
        "\n",
        "train_input_fn = make_input_fn(xg_df_training, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(xg_df_testing, y_testing, num_epochs=1, shuffle=False) # we aren't training it here anymore so 1 epoch and no shuffling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGKwnjT37uJ"
      },
      "source": [
        "feature_columns = ['XLocation', 'YLocation', 'Strength', 'Goal']\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "\n",
        "linear_est.train(train_input_fn)  # uses the passed function \"train_input_fn\" to grab data and train the model\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by running the model on testing data\n",
        "\n",
        "# lets see how accurate the model is\n",
        "print(result['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u00n8uQDfh70"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuniANU4fieP"
      },
      "source": [
        "# Let's make some predictions\n",
        "\n",
        "We can predict the expected goals of an event (x,y,strength) using the `.predict()` method. Using the `.predict()` method, we'll be able to predict the expected goals and generate heat maps for each strength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0yHczQdf0FK"
      },
      "source": [
        "#import prediction data from csv\n",
        "xg_df_predict = pd.read_csv('https://github.com/r-wisniewski/xG-LinearModel/blob/main/prediction.csv')\n",
        "\n",
        "# generate the prediction input function\n",
        "pred_input_fun = make_input_fn(xg_df_predict, y_testing, num_epochs=1, shuffle=False)\n",
        "\n",
        "# cast the predict return to a list. If not casted use next(pred_xxxx)\n",
        "pred_dicts = list(linear_est.predict(pred_input_fn)) # this returns a predictions array (whether or not the event is a goal) for EACH input test data \n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts]) # take each prediction array and strip off the 2nd element ([1]) which is the chance of this event being a goal. Add to a pd.series."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}