{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AHL-xG-LinearModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNODEPrk/eqddUMv92aF7Tc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-wisniewski/xG-LinearModel/blob/main/AHL_xG_LinearModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDoI6m4LQUll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac59b277-660f-40ab-fd03-26c7f104cb13"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "\r\n",
        "!pip install -q sklearn\r\n",
        "\r\n",
        "#from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt # Dataset visualization.\r\n",
        "import numpy as np              # Low-level numerical Python library.\r\n",
        "import pandas as pd             # Higher-level numerical Python library.\r\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ-PHCkjZpzq"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Import scraped data\n",
        "\n",
        "This step imports scraped event data (using ahl_scraper.py) from a csv file. Once imported, the labels and data are separated.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evL7TpeBZ03k"
      },
      "source": [
        "#import training and test data from csv's\r\n",
        "xg_df_train = pd.read_csv()\r\n",
        "xg_df_testing = pd.read_csv()\r\n",
        "\r\n",
        "# separate the labels and data\r\n",
        "y_train = xg_df_train.pop('Goal')\r\n",
        "y_testing = xg_df_testing.pop('Goal')\r\n",
        "\r\n",
        "#check the first few rows of both dataframes\r\n",
        "xg_df_train.head()\r\n",
        "t_train.head()\r\n",
        "\r\n",
        "#check the first few rows of both dataframes\r\n",
        "xg_df_testing.head()\r\n",
        "y_testing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-666rU9qZHM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Let's train!\n",
        "Now that both the training and test data have been collected, let's train the model!\n",
        "\n",
        "Since all the data is numerical, there is no need to convert any categorical data to numerical. Newer AHL game summaries are beginning to track types of shots, when enough of those game summaries are available we could implement shot type as an additional feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3Fh8RlrIDW"
      },
      "source": [
        "### Create the input function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyeZIbiQrNAt"
      },
      "source": [
        "# data_df = all data in table form, label_df = all associated labels in table form\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    # Convert the pandas dataframe into a tf.data.Dataset object. We want to convert our pandas \"table\" to this new object type before processing.\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its associated label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  ####### return a function object for use ######\n",
        "\n",
        "train_input_fn = make_input_fn(xg_df_training, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(xg_df_testing, y_testing, num_epochs=1, shuffle=False) # we aren't training it here anymore so 1 epoch and no shuffling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGKwnjT37uJ"
      },
      "source": [
        "feature_columns = ['XLocation', 'YLocation', 'Strength', 'Goal']\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "\n",
        "linear_est.train(train_input_fn)  # uses the passed function \"train_input_fn\" to grab data and train the model\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by running the model on testing data\n",
        "\n",
        "# lets see how accurate the model is\n",
        "print(result['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}